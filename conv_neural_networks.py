# -*- coding: utf-8 -*-
"""conv_neural_networks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y78w3enlSEq32XRajSI0Z2WQgqWP_a2e

# Second graded assignment: convolutional neural networks

## 1. Imports, Drive mounting, helper function(s)
"""

# Commented out IPython magic to ensure Python compatibility.
try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass

# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras

print(tf.__version__)

# Helper libraries
import numpy as np
import matplotlib.pyplot as plt
import sklearn as sk
import pandas as pd

# fix random seed for reproducibility
seed = 2021
np.random.seed(seed)  
tf.random.set_seed(seed)

import sklearn as sk
from sklearn.model_selection import train_test_split

from tensorflow.keras.datasets import cifar100
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation
from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D
from tensorflow.keras.constraints import max_norm
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.models import load_model

#uncomment if you want to use Drive

from google.colab import drive
drive.mount('/content/gdrive')


#!ls '/content/gdrive/My Drive/'

"""## 2. Assignment overview

Since we have now definitely concluded that MNIST is too easy, we will move to a slightly more difficult data set to play with. It is called CIFAR100 (https://www.cs.toronto.edu/~kriz/cifar.html) and contains (still TINY) natural images of objects in 20 different classes, each with 5 sub-classes (100 classes in total).

To make the problem slightly easier, we will only use the coarse differentiation into 20 classes.

## Loading the data

In the code below, we load the data. The option 'coarse' selects the 20-class version (instead of the 100-class version).

This code is mostly re-used from the first assignment.
"""

# Load the data: CIFAR100 with 20 class labels
(x_train_all, r_train_all_class), ( x_test, r_test_all_class  ) = cifar100.load_data(label_mode='coarse')

num_classes = 20

val_size = 6000
# make validation set
x_train, x_val, r_train_class, r_val_class = train_test_split(x_train_all, r_train_all_class, test_size=val_size, random_state=0)

# let's again take a subset of the training data first, for playing around
# Note that such a subset is only useful if it can guide your tuning process,
# i.e., if it leads you to similar decisions as you would make on the whole training set

# You can again use a subset of the training data for initial exploration
# In this case, 10000 samples is really too small, so we suggest 20000

x_train_small = x_train[:20000]
r_train_small_class = r_train_class[:20000]

# And we do the same standardization as in the first assignment
x_train_all = x_train_all.astype('float32')
x_train = x_train.astype('float32')
x_train_small = x_train_small.astype('float32')
x_val = x_val.astype('float32')
x_test = x_test.astype('float32')

x_train_all /= 255.0
x_train /= 255.0
x_train_small /= 255.0
x_val /= 255.0
x_test /= 255.0

# the labels from the downloaded data are integer numbers
# for a multi-class classification task, we again convert each integer
# to a vector with 19 zeros and a single '1', corresponding to the right class
r_train_all = tf.keras.utils.to_categorical(r_train_all_class, num_classes)
r_train = tf.keras.utils.to_categorical(r_train_class, num_classes)
r_train_small = tf.keras.utils.to_categorical(r_train_small_class, num_classes)
r_val = tf.keras.utils.to_categorical(r_val_class, num_classes)
r_test_class = tf.keras.utils.to_categorical(r_test_all_class, num_classes)



# Labels
labels = [
'aquatic mammals',
'fish',
'flowers',
'food containers',
'fruit and vegetables',
'household electrical devices',
'household furniture',
'insects',
'large carnivores',
'large man-made outdoor things',
'large natural outdoor scenes',
'large omnivores and herbivores',
'medium-sized mammals',
'non-insect invertebrates',
'people',
'reptiles',
'small mammals',
'trees',
'vehicles 1',
'vehicles 2'
]

print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_val.shape[0], 'validation samples')

print('r_train_all:', r_train_all.shape)

print('x_test class:', r_test_class.shape)

print('x_test shape:', x_test.shape)

"""Note the shape of the training data. In the previous assignment, we had grayscale images, consisting of 28x28 pixels. As we were using Dense networks then, we flattened the pixels into a single vector per image. We will now be using convolutional networks, which means we need to keep all pixel values in 2D arrays.

In addition, in the current assignment, the data consists of **colour** images, which means that each image consists of 3 arrays of pixels (RGB: red, green, blue). Every sample is now a tensor of 32x32x3 numbers. 

It is a general agreement that the **first** dimension of the training data always reflects the number of samples and all other dimensions are the sample dimensions. Hence, our complete training set is a tensor of shape (44000, 32, 32, 3). When training with batches, each batch will be a tensor of shape (batch_size, 32, 32, 3).

The images are very low resolution, to the extent where it is often even hard for humans to recognise what is on them. Considering that there are less training samples than in the first assignment, that there are twice as many classes and the data is more complex, it is clear that this task is a lot more difficult. Below are a few examples of the training data:


"""

f = plt.figure(figsize=(20,10))
for idx in range(15):
    plt.subplot(3,5,idx+1)
    plt.subplots_adjust(hspace=0.5)
    plt.title(labels[r_train_class[idx,0]])
    plt.imshow(x_train[idx],  interpolation='None')

"""# An initial model to show how it's done

The code below shows a simple example of a convolutional neural network.
"""

'''Train a simple CNN on the CIFAR100 small images dataset.
Initial model based on example networks used for CIFAR10
e.g., https://keras.io/examples/cifar10_cnn/
'''

# Recall the two main structural paramameters of a network: layer width and network depth
#
# - Layer width determines how many "different things" can be extracted by a layer. 
# - depth determines the complexity of the features that can be extracted

# In convnets, layers are often organised in blocks of layers with the same width, 
# followed by a pooling step to reduce the layer size
# This again allows more complex features to be extracted between pooling steps 

# The first conv layers have 32 filters (channels) with filter size 3x3
# note that this has no relation with the image size, which just happens to be 32x32 pixels!

def initial_model():
  model = Sequential()

  # Convolutional layers
  model.add(Conv2D(64, (3, 3), padding='same',input_shape=x_train.shape[1:]), )
  model.add(BatchNormalization())
  model.add(Activation('relu'), )
  model.add(Conv2D(64, (3, 3), padding='same'),)
  model.add(BatchNormalization())
  model.add(Activation('relu'),)
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Dropout(0.3))

  
  model.add(Conv2D(128, (3, 3), padding='same'))
  model.add(BatchNormalization())
  model.add(Activation('relu'))
  model.add(Conv2D(128, (3, 3), padding='same'))
  model.add(BatchNormalization())
  model.add(Activation('relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Dropout(0.5))
  

  model.add(Conv2D(256, (3, 3), padding='same'))
  model.add(BatchNormalization())
  model.add(Activation('relu'))
  model.add(Conv2D(256, (3, 3), padding='same'))
  model.add(BatchNormalization())
  model.add(Activation('relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Dropout(0.5))
  

  # model.add(Conv2D(512, (3, 3), padding='same'))
  # model.add(BatchNormalization())
  # model.add(Activation('relu'))
  # model.add(Conv2D(512, (3, 3), padding='same'))
  # model.add(BatchNormalization())
  # model.add(Activation('relu'))
  # model.add(MaxPooling2D(pool_size=(2,2)))
  # model.add(Dropout(0.7))
  
  # end of convolutional layers, start of 'hidden' dense layers (can be more than 1 if necessary)
  model.add(Flatten())
  model.add(Dense(256))
  model.add(Activation('relu'),)
  model.add(Dropout(0.5))

  # Final dense layer = linear classifier
  model.add(Dense(num_classes))
  model.add(Activation('softmax'))

  opt = tf.keras.optimizers.Adam() #using defaults for now

  model.compile(loss='categorical_crossentropy',
                optimizer=opt,
                metrics=['accuracy'])

  return model

"""Some information about the model code:

- Just like for the Dense network, the input shape must be specified in the first layer. Where this was only a single number (the number of features) previously, it is now the dimension of a single training sample, so (32,32,3). The Conv2D layer expects a stack of 2D arrays as input. The first two dimensions of the input shape are the dimensions of these arrays, the third dimension is the number of 'channels' (see theory).
- Padding (same) is used here for all conv layers. This is quite standard and avoids you having to keep track of channel shapes (input and output channels of conv layers are equal if padding is used).
- As pooling reduces the size of each channel, it is common to increase the number of filters throughout the layers. This way spatial features (things you see on the image) are gradually translated into abstract features (concepts that are useful to make the classification).
- The code also shows a common practice of combining a few conv layers with the same dimensions before pooling. Note that this is not necessary, it's just how it is often done.
- If you use batchnorm, it is generally advised to put it **before** the activation, i.e., between the convolution and the ReLu (or other) nonlinearity. This is not possible if you specify the nonlinearity as a parameter of the conv layer. We have therefore split it off as a separate layer in the code above.
- Dropout is typically applied on the inputs of a layer, i.e., **after** the nonlinearity of the previous layer (see commented examples). Typically, the more parameters a layer has, the more dropout you will be able to use.
- After the last conv layer, you need to reshape all the remaining features into a single vector again, such that they can be input into the Dense layer(s). This is what the 'Flatten()' layer does - an alternative is to combine the last pooling layer and the Flatten layer into a global pooling layer, which retains only one feature per channel (Max or Average, see docs for more info).
"""

batch_size = 512
epochs = 200

# checkpoint and early stopping code from first assignment is introduced in comments:
# use or replace by your preferred workflow 
# do not forget to reload best model for evaluation after using early stopping (re-use code from first assignment)

checkpoint_dir = "/content/gdrive/My Drive/Colab Notebooks/final_model_no_save/"
print("Models will be saved in ",checkpoint_dir)
model_savename = checkpoint_dir+"final_model"
checkpoint_path = checkpoint_dir+"cp-{epoch:04d}.ckpt"


model_1 = initial_model()
model_1.summary()

#code for modelcheckpoint and early stopping  commented below
cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, 
                                                 monitor='val_accuracy',
                                                 save_weights_only=True,
                                                 save_best_only=True,
                                                verbose=1)
stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=32,min_delta=0.00001)

history_1 = model_1.fit(x_train, r_train,
          batch_size=batch_size,
          epochs=epochs,
          validation_data=(x_val, r_val),
          callbacks = [cp_callback, stopping_callback],
          shuffle=True)

# Run code below to save the weights of final trained model:
# (not very useful in combination with modelcheckpoint, because then you would revert to the best model afterwards)
#model_1.save_weights(model_savename)

# We analyse the result:

[train_loss, train_accuracy] = model_1.evaluate(x_train, r_train, verbose=0)
print("Training set Accuracy:{:7.4f}".format(train_accuracy))
print("Training set Loss:{:7.4f}\n".format(train_loss))

[val_loss, val_accuracy] = model_1.evaluate(x_val, r_val, verbose=0)
print("Validation set Accuracy:{:7.4f}".format(val_accuracy))
print("Validation set Loss:{:7.4f}\n".format(val_loss))

#Now we visualise what happened during training
plot_history(history_1)

"""

One of the first things you should do if you want to make deeper networks is therefore counteract vanishing gradients by introducing batchnormalisation (or later: adding skip-connections, see, e.g., https://keras.io/examples/cifar10_resnet/ - note that this requires some more advanced coding!). You can introduce batchnormalisation after each layer. Since batchnorm also acts as a regulariser (see theory), you may also see a decrease in overfitting. A final hint: batchnorm tends to combine well with maxnorm (and dropout, obviously).

"""



#helper functions for visualisation
import pathlib
# same function as in the getting started notebook, 
# but now plotting the loss functions used in this notebook
# we plot the loss we want to optimise on th eleft (in this case: accuracy)
def plot_history_acc(history):

  # set working directory
  os.chdir(checkpoint_dir)

  plt.figure(figsize = (8,8))

  plt.xlabel('Epoch')
  plt.ylabel('Accuracy')

  plt.plot(history.epoch, np.array(history.history['accuracy']),'g-',
           label='Train accuracy')
  plt.plot(history.epoch, np.array(history.history['val_accuracy']),'r-',
           label = 'Validation accuracy')
  

  # Find latest checkpoint
  # Sort the checkpoints by modification time.
  checkpoints = pathlib.Path(checkpoint_dir).glob("*.index")
  checkpoints = sorted(checkpoints, key=lambda cp:cp.stat().st_mtime)
  checkpoints = [cp.with_suffix('') for cp in checkpoints]
  latest = str(checkpoints[-1])

  best_model_1 = initial_model() # this is a new model
  best_model_1.load_weights(latest)
    
  [val_loss, val_accuracy] = best_model_1.evaluate(x_val, r_val, verbose=0)
  [train_loss, train_accuracy] = best_model_1.evaluate(x_train, r_train, verbose=0)
  plt.title("Best model: Train set Accuracy:{:7.4f}, Val set Accuracy:{:7.4f}".format(train_accuracy, val_accuracy))
  plt.savefig('accuracy_plots.png')



  plt.legend()


#helper functions for visualisation

# same function as in the getting started notebook, 
# but now plotting the loss functions used in this notebook
# we plot the loss we want to optimise on th eleft (in this case: accuracy)
def plot_history_loss(history):
  # set working directory
  os.chdir(checkpoint_dir)


  plt.figure(figsize = (8,8))


  plt.xlabel('Epoch')
  plt.ylabel('Loss minimised by model')
  plt.plot(history.epoch, np.array(history.history['loss']),'g-',
           label='Train loss')
  plt.plot(history.epoch, np.array(history.history['val_loss']),'r-',
           label = 'Validation loss')
  

  # Find latest checkpoint
  # Sort the checkpoints by modification time.
  checkpoints = pathlib.Path(checkpoint_dir).glob("*.index")
  checkpoints = sorted(checkpoints, key=lambda cp:cp.stat().st_mtime)
  checkpoints = [cp.with_suffix('') for cp in checkpoints]
  latest = str(checkpoints[-1])

  best_model_1 = initial_model() # this is a new model
  best_model_1.load_weights(latest)
  
  [val_loss, val_accuracy] = best_model_1.evaluate(x_val, r_val, verbose=0)
  [train_loss, train_accuracy] = best_model_1.evaluate(x_train, r_train, verbose=0)

  plt.title("Best model: Train set Loss:{:7.6f}, Val set Loss:{:7.6f}".format(train_loss, val_loss))
  plt.savefig('log_loss.png')

  
  plt.legend()

plot_history_acc(history_1)
plot_history_loss(history_1)

"""## 3. Augmentation

When using data augmentation on large data sets, it is not feasible to generate the augmented samples up-front. Instead, they are generated 'on the fly' when reading in batches: before each training sample is used in a batch, it is first augmented, so each time the same original sample is used, its augmented version is different. This is done using an ImageDataGenerator.

Before actually using augmentation, it is usually a good idea to have a look at some augmented images. The code block below shows how you can do this.

Data Agumentation strategy 
- small shift 0.1 and 20 degree rotation

What is the effect on training and validation data curves??
"""

# An object from the class ImageDataGenerator will do 'on-the-fly' data augmentation
# every time you call its function .flow()

# Note that not all options are used here: check the docs for additional info
# the class also contains a 'hook' for adding your own augmentation functions

datagen = ImageDataGenerator(
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180) - note that rotation is more compute-intensive than shifting!!
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False,  # randomly flip images
        fill_mode = 'nearest', # what to do with 'new' pixels that occur as the result of a transformation
        zoom_range = 0.1)  

# select and show an image from the training set
img_index = 0

plt.figure()
plt.imshow(x_train[img_index],  interpolation='None')
plt.title("Original image")
plt.show()

testit = datagen.flow(x_train[img_index:img_index+1], batch_size=1)

# generate 15 augmented images (the first one is the original image)
f = plt.figure(figsize=(20,10))
for idx in range(15):
    plt.subplot(3,5,idx+1)
    plt.subplots_adjust(hspace=0.5)
    plt.title("Augmented image")
    plt.imshow(testit.next()[0,:,:,:],  interpolation='None')
plt.show()

"""
**Using augmentation in model training**:
In the code block below, you can see how you can compile and train the same model with data augmentation. It also includes early stopping. 

You wil notice that training now takes longer because of the image preprocessing (augmentation) that is required!

For this reason it is advisable to first tune your network without augmentation. You want to get into a regime where you are still overfitting and you have a clear indication that more data would help, for example by comparing training and validation scores for two training set sizes (e.i., two points of a learning curve), or when you find that considerable overfitting remains, but adding any other type of regularisation makes validation performance worse. 

Then, check which types and levels of augmentation actually help by switching back to the small data set (comparing train and validation scores for unaugmented training and augmented training, where everything else is kept constant). Since this is rough exploration, you can also save time by setting your patience values a bit lower. Once you think you have good augmentation settings, switch back to the larger training set an do a full-blown training run.

**Warning** running the code below takes considerably longer!!
"""

batch_size = 512
epochs = 250

au_model = initial_model()
#au_model.load_weights(latest)
au_model.summary()
au_model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# dummy file path here ... this is local on Colab!
filepath = '/content/gdrive/My Drive/Colab Notebooks/model_width0.1_height0.1_zoom0.1.h5'

callbacks = [EarlyStopping(monitor='val_accuracy', patience=50),
             ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True)]

datagen = ImageDataGenerator(
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180) - note that rotation is more compute-intensive than shifting!!
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False,  # randomly flip images
        fill_mode = 'nearest', # what to do with 'new' pixels that occur as the result of a transformation
        zoom_range = 0.1)  

# Compute quantities required for some augmentation functions
# (e.g., std, mean, and principal components if ZCA whitening is applied).
datagen.fit(x_train, augment=True)

# Fit the model on the batches generated by datagen.flow().
au_history = au_model.fit(datagen.flow(x_train, r_train, batch_size=batch_size),
                                    epochs=epochs, steps_per_epoch=len(x_train) / batch_size,
                                    validation_data=(x_val, r_val),
                                    callbacks = callbacks)

def plot_dual_history(before, after):
  plt.figure(figsize = (20,6))
  plt.subplot(1,2,1)

  plt.xlabel('Epoch')
  plt.ylabel('Accuracy')
  plt.plot(before.epoch, np.array(before.history['accuracy']),'g-',
           label='Initial train accuracy')
  plt.plot(after.epoch, np.array(after.history['accuracy']),'g:',
           label='Final train accuracy')
  plt.plot(before.epoch, np.array(before.history['val_accuracy']),'r-',
           label = 'Initial validation accuracy')
  plt.plot(after.epoch, np.array(after.history['val_accuracy']),'r:',
           label = 'Final validation accuracy')
  plt.ylim([0.0,1.0])
  plt.legend()

  plt.subplot(1,2,2)
  plt.xlabel('Epoch')
  plt.ylabel('Loss minimised by model')
  plt.plot(before.epoch, np.array(before.history['loss']),'g-',
           label='Initial train loss')
  plt.plot(after.epoch, np.array(after.history['loss']),'g:',
           label='Final train loss')
  plt.plot(before.epoch, np.array(before.history['val_loss']),'r-',
           label = 'Initial validation loss')
  plt.plot(after.epoch, np.array(after.history['val_loss']),'r:',
           label = 'Final validation loss')
  plt.legend()


plot_dual_history(history_1, au_history)

model_for_test = initial_model()




# dummy file path here ... this is local on Colab!
filepath = '/content/gdrive/My Drive/Colab Notebooks/final_model_full_data'


callbacks = [EarlyStopping(monitor='val_accuracy', patience=50),
             ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True)]

datagen = ImageDataGenerator(
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180) - note that rotation is more compute-intensive than shifting!!
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False,  # randomly flip images
        fill_mode = 'nearest', # what to do with 'new' pixels that occur as the result of a transformation
        zoom_range = 0.1)  

# We now add batch size to the mix of training parameters
# If you don't specify batch size below, all training data will be used for each learning step
batch_size = 512
epochs = 160

history_for_test =  model_for_test.fit(datagen.flow(x_train_all, r_train_all, batch_size=batch_size),
                                    epochs=epochs, steps_per_epoch=len(x_train_all) / batch_size,
                                    callbacks = callbacks)

plt.figure(figsize = (12,4))
plt.subplot(1,2,1)


plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.plot(history_for_test.epoch, np.array(history_for_test.history['accuracy']),'g-',
        label='Train accuracy')
plt.legend()

plt.subplot(1,2,2)
plt.xlabel('Epoch')
plt.ylabel('Loss minimised by model')
plt.plot(history_for_test.epoch, np.array(history_for_test.history['loss']),'g-',
        label='Train loss')
plt.legend()
plt.show()

#the file type for storing complete models is ".h5"
# feel free to change the path to whatever suits you best!
modelpath = filepath+".h5"

print("Final model saved as ",modelpath)

# Save entire model to a HDF5 file
model_for_test.save(modelpath)

# The code below should give the same results as that for the original model
[train_loss, train_accuracy] = model_for_test.evaluate(x_train_all, r_train_all, verbose=0)


[test_loss, test_accuracy] = model_for_test.evaluate(x_test, r_test_class, verbose=0)

print("Training set Accuracy:{:7.4f}".format(train_accuracy))
print("Training set Loss:{:7.6f}\n".format(train_loss))
print("Test set Accuracy:{:7.4f}".format(test_accuracy))
print("Test set Loss:{:7.6f}\n".format(test_loss))

"""Analysis"""